{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccb0fe8e-6b86-403f-84e0-c910f70bfc23",
   "metadata": {},
   "source": [
    "# JupyterGIS demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e524b05-f463-4727-b212-93bf1450930e",
   "metadata": {},
   "source": [
    "## Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abd406b-717c-4c46-a821-21788826f655",
   "metadata": {},
   "source": [
    "* Aggregate gridded data based on vector regions (e.g. neighborhoods)\n",
    "  * Not straightforward to do in Python\n",
    "* Design:\n",
    "  * Start in a Notebook, prepared with Maryamâ€™s expertise\n",
    "  * Loading GeoPandas, tools for Zonal Statistics\n",
    "  * Programmatically create .jGIS document, add input data sources and output data sources.\n",
    "  * Demonstrate collaboration of JGIS alongside Notebook. Annotation, ad layer from catalog, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6282c2cd-f189-4f07-8d8f-0ec75b19e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path().cwd() / \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6c573e-757c-416c-a35a-fa6bbb462fc8",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "* https://www.geopythontutorials.com/notebooks/xarray_zonal_stats.html?utm_source=chatgpt.com#data-pre-processing\n",
    "* Carl's class\n",
    "  * https://espm-288.carlboettiger.info/tutorials/python/spatial-2.html\n",
    "  * https://espm-288.carlboettiger.info/tutorials/python/spatial-1.html\n",
    "  * https://espm-288.carlboettiger.info/tutorials/python/spatial-3.html\n",
    "  * https://espm-288.carlboettiger.info/tutorials/python/spatial-4.html\n",
    "* https://carpentries-incubator.github.io/geospatial-python/10-zonal-statistics.html\n",
    "* https://medium.com/data-science/zonal-statistics-algorithm-with-python-in-4-steps-382a3b66648a\n",
    "* https://automating-gis-processes.github.io/CSC18/lessons/L6/zonal-statistics.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941c869f-4726-4363-ac71-95440a475386",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## From geopythontutorials.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b259e2b-0758-430d-ba4e-d48184395473",
   "metadata": {},
   "source": [
    "https://www.geopythontutorials.com/notebooks/xarray_zonal_stats.html?utm_source=chatgpt.com\n",
    "\n",
    "New dependencies\n",
    "\n",
    "* rioxarray\n",
    "* geocube\n",
    "* xarray-spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a3aa9d-1a0e-4065-b7c3-b99492a81800",
   "metadata": {},
   "source": [
    "### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7b45a4-c41a-4c68-8fa2-d7472898af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_folder = \"data\"\n",
    "\n",
    "def download(url, data_folder):\n",
    "    filename = os.path.join(data_folder, os.path.basename(url))\n",
    "    if not os.path.exists(filename):\n",
    "        from urllib.request import urlretrieve\n",
    "        local, _ = urlretrieve(url, filename)\n",
    "        print('Downloaded ' + local)\n",
    "\n",
    "raster_file = 'chirps-v2.0.2021.tif'\n",
    "zones_file = 'cb_2021_us_county_500k.zip'\n",
    "\n",
    "files = [\n",
    "    'https://data.chc.ucsb.edu/products/CHIRPS-2.0/global_annual/tifs/' + raster_file,\n",
    "    'https://www2.census.gov/geo/tiger/GENZ2021/shp/' + zones_file,\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "  download(file, data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742d07d7-e745-4e9f-8c46-2662be64e54f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aa7d8f-51a5-4022-b784-5c6021053f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "zones_file_path = os.path.join(data_folder, zones_file)\n",
    "\n",
    "zones_df = gpd.read_file(zones_file_path)\n",
    "# TODO: Louisiana instead?\n",
    "california_df  = zones_df[zones_df['STATE_NAME'] == 'California'].copy()\n",
    "california_df.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ead58b-fd90-4a30-8cc3-f94b362f09f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "california_df['GEOID'] = california_df.GEOID.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da98d0a2-b1cc-4a6b-8754-2df48918c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray as rxr\n",
    "\n",
    "raster_filepath = os.path.join(data_folder, raster_file)\n",
    "raster = rxr.open_rasterio(raster_filepath, mask_and_scale=True)\n",
    "clipped = raster.rio.clip(california_df.geometry)\n",
    "clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f81cff-8836-43c1-9477-4950b771bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation = clipped.sel(band=1)\n",
    "precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f55b7-081b-43ec-9bbb-55295a1cb42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geocube.api.core import make_geocube\n",
    "\n",
    "california_raster = make_geocube(\n",
    "    vector_data=california_df,\n",
    "    measurements=['GEOID'],\n",
    "    like=precipitation,\n",
    ")\n",
    "california_raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216b6a74-b543-4896-8348-f84b80babecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xrspatial import zonal_stats\n",
    "\n",
    "stats_df = zonal_stats(zones=california_raster.GEOID, values=precipitation)\n",
    "stats_df.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae05145f-b31c-4d10-8c3e-852c722fa0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df['GEOID'] = stats_df['zone'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa371396-e42b-4c18-a07f-7d2eb8cb0ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = california_df.merge(stats_df[['GEOID', 'mean']], on='GEOID')\n",
    "joined.iloc[:5, -5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e306fe32-9197-455a-aedb-0d3b24fb215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(10,10)\n",
    "\n",
    "legend_kwds={\n",
    "           'orientation': 'horizontal',  # Make the legend horizontal\n",
    "           'shrink': 0.5,  # Reduce the size of the legend bar by 50%\n",
    "           'pad': 0.05,  # Add some padding around the legend\n",
    "           'label': 'Precipitation (mm)',  # Set the legend label (optional)\n",
    "       }\n",
    "joined.plot(ax=ax, column='mean', cmap='Blues',\n",
    "          legend=True, legend_kwds=legend_kwds)\n",
    "ax.set_axis_off()\n",
    "ax.set_title('Total Precipitation 2021 for California Counties')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d1499-fb42-437e-a979-88ddb74f4822",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d63cc59-78cd-4639-9c96-f6ac3e0dd208",
   "metadata": {},
   "source": [
    "## From Carl's class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b27ffc-7f33-4374-b0a8-160bd3c50567",
   "metadata": {},
   "source": [
    "New dependencies (don't add to environment, this is just for accessing data):\n",
    "\n",
    "* ibis-duckdb\n",
    "* odc-stac\n",
    "* cmasher\n",
    "\n",
    "New dependencies (add to environment):\n",
    "\n",
    "* exactextract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2670f48f-c81d-472e-a556-496f12e3f8c4",
   "metadata": {},
   "source": [
    "### Setting up vector data (neighborhoods)\n",
    "\n",
    "https://espm-288.carlboettiger.info/tutorials/python/spatial-3.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc77b3-a2dc-4356-86ff-6a9d617231d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "INEQUALITY_GPKG_FILENAME = \"mappinginequality.gpkg\"\n",
    "INEQUALITY_GPKG_FILE = INEQUALITY_DATASET_FILE_PARENTDIR / INEQUALITY_GPKG_FILENAME\n",
    "\n",
    "def ensure_inequality_data():\n",
    "    \"\"\"Bring the inequality dataset onto the local filesystem.\n",
    "\n",
    "    This shouldn't be necessary, and it would be best to demo this with cloud access,\n",
    "    but accessing the data directly using /viscurl/ isn't working as expected.\n",
    "    \"\"\"\n",
    "    if INEQUALITY_GPKG_FILE.is_file():\n",
    "        print(f\"Inequality dataset already present at '{INEQUALITY_GPKG_FILE}'.\")\n",
    "        return\n",
    "    \n",
    "    inequality_dataset_url_parent = \"https://dsl.richmond.edu/panorama/redlining/static\"\n",
    "    inequality_dataset_url = f\"{inequality_dataset_url_parent}/{INEQUALITY_GPKG_FILENAME}\"\n",
    "\n",
    "    response = requests.get(inequality_dataset_url)\n",
    "    with open(INEQUALITY_GPKG_FILE, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Inequality dataset downloaded to '{INEQUALITY_GPKG_FILE}'.\")\n",
    "\n",
    "ensure_inequality_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936e26c2-05ca-48b4-990d-7097b51e93ac",
   "metadata": {},
   "source": [
    "### Setting up raster data (NDVI)\n",
    "\n",
    "https://espm-288.carlboettiger.info/tutorials/python/spatial-3.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf53f2b-657d-4683-9518-8257a93e5a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibis\n",
    "from ibis import _\n",
    "\n",
    "INEQUALITY_GEOJSON_FILE = DATA_DIR / str(INEQUALITY_GPKG_FILE).replace(\".gpkg\", \".geojson\")\n",
    "\n",
    "con = ibis.duckdb.connect(extensions=[\"spatial\"])\n",
    "\n",
    "# TODO: Why doesn't this work?\n",
    "# \"does not exist in the file system, and is not recognized as a supported dataset name\"\n",
    "# redlines = (\n",
    "#     con\n",
    "#     .read_geo(\"/vsicurl/https://dsl.richmond.edu/panorama/redlining/static/mappinginequality.gpkg\")\n",
    "#     .filter(_.city == \"New Haven\", _.residential)\n",
    "# )\n",
    "redlines = (\n",
    "    con\n",
    "    .read_geo(INEQUALITY_GPKG_FILE)\n",
    "    .filter(_.city == \"New Haven\", _.residential)\n",
    ")\n",
    "city =  redlines.execute().set_crs(\"EPSG:4326\")\n",
    "city.to_file(INEQUALITY_GEOJSON_FILE, engine=\"fiona\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e330a840-5140-4528-84a3-59c1162df425",
   "metadata": {},
   "outputs": [],
   "source": [
    "city.explore(column=\"grade\", cmap=\"inferno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e13f25-47ec-4fdb-9d37-bb693952980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "box = city.total_bounds\n",
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61363fcb-e942-489e-a631-9cfb5db72800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystac_client import Client\n",
    "\n",
    "items = (\n",
    "  Client.\n",
    "  open(\"https://earth-search.aws.element84.com/v1\").\n",
    "  search(\n",
    "    collections = ['sentinel-2-l2a'],\n",
    "    bbox=box,\n",
    "    datetime = \"2024-06-01/2024-09-01\",\n",
    "    query={\"eo:cloud_cover\": {\"lt\": 20}}).\n",
    "  item_collection()\n",
    ")\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814ce3ab-c48b-4ee5-b7b1-2572ee6fb305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import odc.stac\n",
    "\n",
    "data = odc.stac.load(\n",
    "    items,\n",
    "    bands=[\"nir08\", \"red\"],\n",
    "    bbox=box,\n",
    "    resolution=10, # the native resolution is already 10m.  Increase this to ~ 100m for larger cities.\n",
    "    groupby=\"solar_day\",\n",
    "    chunks = {} # this tells odc to use dask\n",
    "    \n",
    ")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc33ba4-428e-4668-830f-874c952f8a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "\n",
    "p = data.red.plot.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5da8801-f87d-4b9a-a368-b6dba634e17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nir08.plot.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7272e420-bef5-4dfc-8bae-2448f5b7f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi = (\n",
    "    ((data.nir08 - data.red) / (data.red + data.nir08))\n",
    "    .median(\"time\", keep_attrs=True)\n",
    ")\n",
    "\n",
    "ndvi = ndvi.where(ndvi < 1).compute()\n",
    "\n",
    "ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535f7586-3fd1-4bd9-ac53-a21952275fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: (nitpick) Why is it blurry even when I set no/nearest interpolation?\n",
    "# It's blurry on Carl's website too. I feel like I've solved this before... :)\n",
    "ndvi.plot.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f55d372-ede0-44d1-8100-c8307c6dd7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "\n",
    "ndvi.rio.reproject(\n",
    "    \"EPSG:4326\",\n",
    ").rio.to_raster(\n",
    "    raster_path=DATA_DIR / \"ndvi.tif\", \n",
    "    driver=\"COG\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dc8024-095a-4553-a0ac-2b7f090e59aa",
   "metadata": {},
   "source": [
    "### Zonal statistics\n",
    "\n",
    "https://espm-288.carlboettiger.info/tutorials/python/spatial-4.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a169692a-2674-4c4e-ab88-50ba908083d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exactextract import exact_extract\n",
    "\n",
    "city_stats = exact_extract(\n",
    "    DATA_DIR / \"ndvi.tif\", \n",
    "    city, \n",
    "    \"mean_ndvi=mean\", \n",
    "    include_geom = True,\n",
    "    include_cols=[\"label\", \"grade\", \"city\", \"fill\"],\n",
    "    output=\"pandas\",\n",
    ")\n",
    "\n",
    "city_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1a5c90-aaa3-4e60-a188-f0a2e4b2201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_stats.explore(column=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df029e33-1702-4e3b-8390-70b6e2e6fb15",
   "metadata": {},
   "source": [
    "TODO: JupyterGIS-ify"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
